{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPffG2HudPqH+kggMA09Qhh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManG0A2/MLP-class/blob/main/4_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nxLGqAh5K0bz"
      },
      "outputs": [],
      "source": [
        "#앙상블 학습\n",
        "#정형 데이터를 다루는데 가장 뛰어난 알고리즘\n",
        "#결정 트리를 기반"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤 포레스트\n",
        "#결정트리는 각 특성마다 하나가 남을때까지 분류하기에 과대적합 될 가능성이 높음\n",
        "#그래서 특성을 제한하는 방식을 사용\n",
        "\n",
        "#1. 훈련하기 위한 데이터를 랜덤하게 만든다.\n",
        "#-랜덤하게 추출한 부트스트랩 샘플을 만듬(중복된 샘플 추출 가능)\n",
        "# 하나 뽑고 다시 넣고 다시 뽑고 반복\n",
        "#부트 스트랩 샘플은 주로 훈련 세트와 같은 크기로 만든다 25%정도\n",
        "\n",
        "#2. 부트스트랩 샘플로 결정 트리를 훈련\n",
        "#-특성 집합의 루트 갯수만큼 램덤 선택해 그중에서 또 최선의 분할을 선택\n",
        "#-위는 분류만 해당되고 회귀의 경우는 모든 특성집합을 사용한다.\n",
        "\n",
        "#3. 정해진 수만큼 위 과정을 반복"
      ],
      "metadata": {
        "id": "BqqNPmUpLH_I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split( data, target, test_size = 0.2, random_state=42,stratify=target)"
      ],
      "metadata": {
        "id": "957qk2ijNcWC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "\n",
        "scores = cross_validate( rf, train_input, train_target,\n",
        "                       return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3IbAnIbNhcd",
        "outputId": "212edd59-f5b5-4b11-9b48-9f0fc14cd8ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9981720130385032 0.8937817428000298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#특성 중요도\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puFV7WLVNlB1",
        "outputId": "e0174ce7-22ec-400e-e645-c8793ce25aa7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2301315  0.50081183 0.26905668]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "이 결과를 앞의 1절 '결정 트리'에서 만든 특성 중요도와 비교해보자. 결정트리에서 특성 중요도는 다음과 같았다.\n",
        "\n",
        "0.12345626 , 0.86862934 , 0.0079144\n",
        "\n",
        "각각 [알코올 도수, 당도, PH]였는데, 두 번째 특성인 당도의 중요도가 감소하고 알코올 도수와 PH특성의 중요도가 조금 상승했다.\n",
        "이런 이유는 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문이다. 그 결과 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻는다. 이는 과대적합을 줄이고 일반화 성능을 높이는데 도움이 된다.\n",
        "\n",
        "또한 두번째로 랜덤 포레스트의 신기한 특징은 부트스트랩 샘플에 포함되지 않고 남는 샘플이 있다.\n",
        "이런 샘프을 OOB (out of bag) 샘플이라고 한다. 이 남는 샘플을 사용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있다. 마치 검증 세트의 역할을 하는 것이다.\n",
        "이 점수를 얻으려면 RandomForestClassifier 클래스의 oob_score 매개변수를 True로 지정해야 한다.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "nayNbeAePqI6",
        "outputId": "0af2704f-f9ed-465e-9dd5-4aa7f25a1d00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n이 결과를 앞의 1절 '결정 트리'에서 만든 특성 중요도와 비교해보자. 결정트리에서 특성 중요도는 다음과 같았다.\\n\\n0.12345626 , 0.86862934 , 0.0079144\\n\\n각각 [알코올 도수, 당도, PH]였는데, 두 번째 특성인 당도의 중요도가 감소하고 알코올 도수와 PH특성의 중요도가 조금 상승했다. \\n이런 이유는 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문이다. 그 결과 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻는다. 이는 과대적합을 줄이고 일반화 성능을 높이는데 도움이 된다.\\n\\n또한 두번째로 랜덤 포레스트의 신기한 특징은 부트스트랩 샘플에 포함되지 않고 남는 샘플이 있다. \\n이런 샘프을 OOB (out of bag) 샘플이라고 한다. 이 남는 샘플을 사용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있다. 마치 검증 세트의 역할을 하는 것이다.\\n이 점수를 얻으려면 RandomForestClassifier 클래스의 oob_score 매개변수를 True로 지정해야 한다.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OOB 점수 출력\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs= -1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVLyE-27OEJd",
        "outputId": "358b870c-1ac7-4683-b52a-08cdd111fa77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8964787377333077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 엑스트라 트리\n",
        "#랜덤 포레스트랑 비슷하지만 노드를 분할 할 때 최선의 분할을 찾지않고 랜덤으로 분할함.\n",
        "#또한 랜덤 포레스트와 엑스트라 트리의 차이점은 부트스트랩 샘플을 사용하지 않는다는 점이다.\n",
        "#한 마디로 --> 각 결정 트리를 만들 때 전체 훈련 세트를 사용한다. 대신 노드를 분할할 때 가장 좋은 분할을 찾는 것이 아니라 무작위로 분할 하자!\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target,\n",
        "                       return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leId9KI5OMlG",
        "outputId": "45d47255-5e37-4889-a593-01c7ea16467f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9981720130385032 0.8924350336862368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#보통 엑스트라 트리가 무작위성이 좀 더 크기 때문에 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야 한다. 하지만 랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 엑스트라 트리의 장점이다.\n",
        "#아래는 엑스트라 트리에서 특성마다의 의존성\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwXz-4i-O2h2",
        "outputId": "1ab1e2f7-b1bf-435e-a84f-5e8a51ea82f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20321321 0.51571223 0.28107456]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#그레이디언트 부스팅(SGD랑 비슷)\n",
        "#깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 하는 방법\n",
        "#과대적합에 강하다 -> 일반화에 강하다.\n",
        "#디폴트는 깊이가 3개짜리 트리가 100개\n",
        "\n",
        "#이전모델을 점점 보와해가면서 순차적으로 더해나간 후 최종모델을 예측\n",
        "#오차를 줄여나가는 과정"
      ],
      "metadata": {
        "id": "M39Rw6qAO4Vf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target,\n",
        "                       return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsZBFdoDQwhH",
        "outputId": "e14541a0-b3b3-4fb2-de71-f549bb9626d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.886136193834053 0.8714622047827053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습률과 트리의 갯수 증가\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n",
        "                               random_state=42)\n",
        "\n",
        "scores = cross_validate(gb, train_input, train_target,\n",
        "                       return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XhNAS8GQyeo",
        "outputId": "ac88ab4c-a749-4ab6-fb6b-407505b8590f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9442947291395691 0.8751179018286814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3AnLe6qQ2n8",
        "outputId": "15dcce09-57e2-43e8-e78e-7615c51cd0d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.17200523 0.67319793 0.15479683]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#히스토그램 기반 그레이디언트 부스팅\n",
        "\n",
        "#히스토그램 기반 그레이디언트 부스팅은 먼저 입력 특성을 256개의 구간으로 나눈다. 따라서 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있다.\n",
        "#예를 들어 키가 1~512까지 있다면 1,2 는 1 3,4 는 2로 ,, 몇이든 키의 구간을 256개로 나눈다.\n",
        "#과대적합을 억제하면서 위보다 더 좋은 성능"
      ],
      "metadata": {
        "id": "GqpSt1R_RHG4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target,\n",
        "                       return_train_score=True)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp647TedSLSg",
        "outputId": "bbc7b465-aa3b-408f-bddb-420daca4e1e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.930536541746549 0.8780021470348707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target,\n",
        "                                n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbdSTp-pSSJS",
        "outputId": "781bca25-3b21-40f2-d81f-2c336cc674c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09374639 0.23954204 0.08664614]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = permutation_importance(hgb, test_input, test_target,\n",
        "                               n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAQzDBfHSWMf",
        "outputId": "07b8a55d-c17d-4495-d544-9ea0f059c80f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04953846 0.20176923 0.04776923]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuUYzdD6XDzM",
        "outputId": "43b8f8d4-d791-45e2-b9a6-0aa18486b5ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8776923076923077"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target,\n",
        "                       return_train_score=True)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "id": "TEOnb-H9XH67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cee01f1-30dc-450d-bf50-db0277090c2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9524726282724838 0.8785790701117939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GultFVNRRaO",
        "outputId": "8b07b7bd-856e-4a1e-813f-3fedc21864ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9524726282724838 0.8785790701117939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km-WFPb3RW1K",
        "outputId": "b61a5405-fbd0-404e-a3b8-f89c581982c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.934577605325741 0.8805047382838529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPAg-mfZRgdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}